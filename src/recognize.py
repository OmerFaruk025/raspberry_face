import cv2
import time
from collections import deque
from pathlib import Path
from camera import Camera
from face_detect import FaceDetector

# -----------------------------
# AYARLAR
# -----------------------------
MATCH_THRESHOLD = 60        # Kabul eÅŸiÄŸi
COOLDOWN_SECONDS = 3        # TanÄ±ma sonrasÄ± bekleme
SCORE_BUFFER_SIZE = 5       # Ortalama skor iÃ§in frame sayÄ±sÄ±

ROOT_DIR = Path(__file__).resolve().parent.parent
MODEL_PATH = ROOT_DIR / "lbph_model.yml"
LABEL_PATH = ROOT_DIR / "labels.txt"

# -----------------------------
# MODEL & LABEL
# -----------------------------
recognizer = cv2.face.LBPHFaceRecognizer_create()
recognizer.read(str(MODEL_PATH))

labels = {}
with open(LABEL_PATH, "r", encoding="utf-8") as f:
    for line in f:
        idx, name = line.strip().split(":")
        labels[int(idx)] = name

print(f"âœ… Model yÃ¼klendi | KiÅŸi sayÄ±sÄ±: {len(labels)}")

# -----------------------------
# NESNELER
# -----------------------------
cam = Camera()                  # ğŸ”¥ Direkt PiCam
detector = FaceDetector()

score_buffer = deque(maxlen=SCORE_BUFFER_SIZE)
last_recognized_time = 0
face_active = False             # yÃ¼z ekranda mÄ±?

print("ğŸ“¸ Kamera hazÄ±r, tanÄ±ma aktif")

# -----------------------------
# ANA DÃ–NGÃœ
# -----------------------------
try:
    while True:
        now = time.time()

        # ---- COOLDOWN (TANIDIKTAN SONRA HÄ°Ã‡BÄ°R ÅEY YAPMA) ----
        if now - last_recognized_time < COOLDOWN_SECONDS:
            time.sleep(0.2)
            continue

        ret, frame = cam.read()
        if not ret or frame is None:
            time.sleep(0.2)
            continue

        face_img, bbox = detector.detect_and_crop(frame)

        # ---- YÃœZ YOK ----
        if face_img is None:
            face_active = False
            score_buffer.clear()
            time.sleep(0.1)
            continue

        # ---- YÃœZ Ä°LK KEZ ALGILANDI ----
        if not face_active:
            print("ğŸ‘¤ YÃ¼z algÄ±landÄ±")
            face_active = True

        # ---- TANIMA ----
        gray = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)
        gray = cv2.resize(gray, (200, 200))

        label_id, confidence = recognizer.predict(gray)
        match_percent = max(0, int(100 - confidence))
        name = labels.get(label_id, "Bilinmeyen")

        score_buffer.append(match_percent)
        avg_score = sum(score_buffer) / len(score_buffer)

        # ---- KARAR ----
        if avg_score >= MATCH_THRESHOLD:
            print(
                f"âœ… TANINDI â†’ {name.upper()} | "
                f"Benzerlik: %{round(avg_score, 1)}"
            )
            last_recognized_time = time.time()
            face_active = False
            score_buffer.clear()

        else:
            print(
                f"âŒ TanÄ±nmadÄ± | Tahmin: {name} | "
                f"Benzerlik: %{round(avg_score, 1)}"
            )

        # -----------------------------
        # MONITOR TAKARSAN AÃ‡ABÄ°LÄ°RSÄ°N
        # -----------------------------
        # cv2.imshow("Face Recognition", frame)
        # if cv2.waitKey(1) & 0xFF == 27:
        #     break

        time.sleep(0.1)

except KeyboardInterrupt:
    print("\nğŸ‘‹ Sistem kapatÄ±ldÄ±")

finally:
    cam.release()
    # cv2.destroyAllWindows()
